/**
 * AI Knowledge Base
 * Comprehensive data for AI frameworks, vector DBs, embeddings, and local AI
 */

import { AIOption, VectorDBOption, EmbeddingOption, LocalAIOption } from './types';

// AI SDK and Framework options
export const aiFrameworks: AIOption[] = [
  {
    id: 'vercel-ai',
    name: 'Vercel AI SDK',
    category: 'ai',
    description: 'Unified API for building AI-powered applications',
    type: 'sdk',
    streaming: true,
    structuredOutput: true,
    agentSupport: true,
    supportedProviders: ['openai', 'anthropic', 'google', 'mistral', 'cohere', 'huggingface'],
    supportedRuntimes: ['node', 'bun'],
    pros: [
      'Unified API across providers',
      'Excellent streaming support',
      'React hooks included',
      'Great TypeScript support',
      'Active development by Vercel',
    ],
    cons: [
      'Vercel-centric ecosystem',
      'Learning curve for advanced features',
      'Some provider features not exposed',
    ],
    tradeoffs: [
      'Unified API vs. provider-specific features',
      'Abstraction vs. direct control',
      'Convenience vs. flexibility',
    ],
    bestFor: ['Next.js apps', 'Multi-provider AI apps', 'Streaming chat UIs', 'React projects'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: ['OPENAI_API_KEY', 'ANTHROPIC_API_KEY'],
    compatibleWith: ['nextjs', 'hono', 'express', 'openai', 'anthropic', 'google-ai'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸ¤–',
    documentationUrl: 'https://sdk.vercel.ai/docs',
  },
  {
    id: 'langchain',
    name: 'LangChain',
    category: 'ai',
    description: 'Framework for building applications with LLMs',
    type: 'framework',
    streaming: true,
    structuredOutput: true,
    agentSupport: true,
    supportedProviders: ['openai', 'anthropic', 'google', 'cohere', 'huggingface', 'local'],
    supportedRuntimes: ['node', 'bun', 'python'],
    pros: [
      'Comprehensive tool ecosystem',
      'Great for complex chains',
      'RAG support built-in',
      'Active community',
      'Many integrations',
    ],
    cons: [
      'Large bundle size',
      'Can be over-engineered for simple tasks',
      'Frequent breaking changes',
      'Abstraction overhead',
    ],
    tradeoffs: [
      'Power vs. simplicity',
      'Ecosystem vs. bundle size',
      'Flexibility vs. learning curve',
    ],
    bestFor: ['Complex AI pipelines', 'RAG applications', 'Agent systems', 'Multi-step workflows'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: ['OPENAI_API_KEY'],
    compatibleWith: ['openai', 'anthropic', 'pinecone', 'chromadb', 'qdrant'],
    incompatibleWith: [],
    complexity: 'high',
    logoEmoji: 'ðŸ¦œ',
    documentationUrl: 'https://js.langchain.com/docs',
  },
  {
    id: 'llamaindex',
    name: 'LlamaIndex',
    category: 'ai',
    description: 'Data framework for LLM applications',
    type: 'framework',
    streaming: true,
    structuredOutput: true,
    agentSupport: true,
    supportedProviders: ['openai', 'anthropic', 'google', 'local'],
    supportedRuntimes: ['node', 'python'],
    pros: [
      'Best-in-class data ingestion',
      'Excellent for RAG',
      'Index optimization',
      'Query engines',
    ],
    cons: [
      'Steeper learning curve',
      'JS version less mature than Python',
      'Heavy for simple use cases',
    ],
    tradeoffs: [
      'Data handling vs. simplicity',
      'Index power vs. setup complexity',
    ],
    bestFor: ['Document Q&A', 'Knowledge bases', 'RAG applications', 'Data-heavy AI apps'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: ['OPENAI_API_KEY'],
    compatibleWith: ['openai', 'pinecone', 'chromadb', 'qdrant', 'weaviate'],
    incompatibleWith: [],
    complexity: 'high',
    logoEmoji: 'ðŸ¦™',
    documentationUrl: 'https://ts.llamaindex.ai',
  },
  {
    id: 'openai-sdk',
    name: 'OpenAI SDK',
    category: 'ai',
    description: 'Official OpenAI API client',
    type: 'sdk',
    streaming: true,
    structuredOutput: true,
    agentSupport: true,
    supportedProviders: ['openai'],
    supportedRuntimes: ['node', 'bun', 'deno', 'python'],
    pros: [
      'Official SDK',
      'Best GPT model support',
      'Function calling',
      'Assistants API',
      'Vision support',
    ],
    cons: [
      'OpenAI only',
      'Vendor lock-in',
      'Costs can add up',
    ],
    tradeoffs: [
      'Best GPT support vs. vendor lock-in',
      'Features vs. flexibility',
    ],
    bestFor: ['GPT-focused apps', 'Assistants API users', 'Function calling', 'Vision apps'],
    monthlyCost: { free: false, hobbyist: '$5-50', startup: '$50-500', enterprise: 'Custom' },
    requiredEnvVars: ['OPENAI_API_KEY'],
    compatibleWith: ['vercel-ai', 'langchain', 'pinecone', 'chromadb'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸ§ ',
    documentationUrl: 'https://platform.openai.com/docs',
  },
  {
    id: 'anthropic-sdk',
    name: 'Anthropic SDK',
    category: 'ai',
    description: 'Official Anthropic API client for Claude models',
    type: 'sdk',
    streaming: true,
    structuredOutput: true,
    agentSupport: true,
    supportedProviders: ['anthropic'],
    supportedRuntimes: ['node', 'bun', 'python'],
    pros: [
      'Best Claude model support',
      'Tool use support',
      'Long context windows',
      'Great for reasoning tasks',
    ],
    cons: [
      'Anthropic only',
      'Smaller ecosystem than OpenAI',
      'Some features still beta',
    ],
    tradeoffs: [
      'Claude quality vs. ecosystem size',
      'Safety features vs. flexibility',
    ],
    bestFor: ['Claude-focused apps', 'Long-context tasks', 'Reasoning-heavy apps', 'Tool use'],
    monthlyCost: { free: false, hobbyist: '$5-50', startup: '$50-500', enterprise: 'Custom' },
    requiredEnvVars: ['ANTHROPIC_API_KEY'],
    compatibleWith: ['vercel-ai', 'langchain'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸ”®',
    documentationUrl: 'https://docs.anthropic.com',
  },
  {
    id: 'google-ai',
    name: 'Google AI SDK',
    category: 'ai',
    description: 'Google Generative AI SDK for Gemini models',
    type: 'sdk',
    streaming: true,
    structuredOutput: true,
    agentSupport: false,
    supportedProviders: ['google'],
    supportedRuntimes: ['node', 'bun', 'python'],
    pros: [
      'Gemini model access',
      'Multimodal support',
      'Generous free tier',
      'Fast inference',
    ],
    cons: [
      'Google ecosystem only',
      'Less mature than OpenAI',
      'API changes frequently',
    ],
    tradeoffs: [
      'Multimodal vs. ecosystem maturity',
      'Free tier vs. production stability',
    ],
    bestFor: ['Multimodal apps', 'Google Cloud users', 'Cost-conscious projects', 'Vision + text'],
    monthlyCost: { free: true, hobbyist: '$0-20', startup: '$20-200', enterprise: 'Custom' },
    requiredEnvVars: ['GOOGLE_GENERATIVE_AI_API_KEY'],
    compatibleWith: ['vercel-ai', 'langchain'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'âœ¨',
    documentationUrl: 'https://ai.google.dev/docs',
  },
  {
    id: 'mastra',
    name: 'Mastra',
    category: 'ai',
    description: 'TypeScript framework for AI agents and workflows',
    type: 'framework',
    streaming: true,
    structuredOutput: true,
    agentSupport: true,
    supportedProviders: ['openai', 'anthropic', 'google'],
    supportedRuntimes: ['node', 'bun'],
    pros: [
      'TypeScript-first',
      'Agent orchestration',
      'Workflow automation',
      'Built-in integrations',
    ],
    cons: [
      'Newer framework',
      'Smaller community',
      'Less documentation',
    ],
    tradeoffs: [
      'TypeScript focus vs. maturity',
      'Agent features vs. simplicity',
    ],
    bestFor: ['TypeScript AI projects', 'Agent systems', 'Workflow automation'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: ['OPENAI_API_KEY'],
    compatibleWith: ['openai', 'anthropic'],
    incompatibleWith: [],
    complexity: 'medium',
    logoEmoji: 'ðŸŽ­',
    documentationUrl: 'https://mastra.ai/docs',
  },
  {
    id: 'none',
    name: 'No AI Framework',
    category: 'ai',
    description: 'Skip AI integration',
    type: 'sdk',
    streaming: false,
    structuredOutput: false,
    agentSupport: false,
    supportedProviders: [],
    supportedRuntimes: ['node', 'bun', 'deno', 'python', 'go', 'rust'],
    pros: ['Simpler architecture', 'No AI complexity', 'Lower costs'],
    cons: ['No AI features'],
    tradeoffs: ['Simplicity vs. AI capabilities'],
    bestFor: ['Non-AI apps', 'Simple CRUD', 'Traditional web apps'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: [],
    compatibleWith: [],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸš«',
  },
];

// Vector Database options
export const vectorDatabases: VectorDBOption[] = [
  {
    id: 'pinecone',
    name: 'Pinecone',
    category: 'vector-db',
    description: 'Managed vector database for production AI applications',
    hosting: 'managed',
    maxDimensions: 20000,
    hybridSearch: true,
    filtering: true,
    supportedRuntimes: ['node', 'bun', 'python'],
    pros: [
      'Fully managed',
      'Auto-scaling',
      'Great performance',
      'Serverless option',
      'Rich filtering',
    ],
    cons: [
      'Can be expensive',
      'Vendor lock-in',
      'Limited free tier',
    ],
    tradeoffs: [
      'Managed convenience vs. cost',
      'Performance vs. price',
    ],
    bestFor: ['Production RAG', 'Enterprise apps', 'High-scale semantic search'],
    monthlyCost: { free: true, hobbyist: '$25', startup: '$70+', enterprise: 'Custom' },
    requiredEnvVars: ['PINECONE_API_KEY', 'PINECONE_ENVIRONMENT'],
    compatibleWith: ['langchain', 'llamaindex', 'vercel-ai'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸŒ²',
    documentationUrl: 'https://docs.pinecone.io',
  },
  {
    id: 'chromadb',
    name: 'ChromaDB',
    category: 'vector-db',
    description: 'Open-source embedding database',
    hosting: 'self-hosted',
    maxDimensions: 4096,
    hybridSearch: false,
    filtering: true,
    supportedRuntimes: ['node', 'python'],
    pros: [
      'Open source',
      'Easy local development',
      'Good documentation',
      'Python-first',
    ],
    cons: [
      'Limited managed options',
      'Not as performant at scale',
      'Self-hosting required for production',
    ],
    tradeoffs: [
      'Open source vs. managed convenience',
      'Simplicity vs. scale',
    ],
    bestFor: ['Local development', 'Prototypes', 'Python projects', 'Open-source preference'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: ['CHROMA_HOST'],
    compatibleWith: ['langchain', 'llamaindex'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸŽ¨',
    documentationUrl: 'https://docs.trychroma.com',
  },
  {
    id: 'qdrant',
    name: 'Qdrant',
    category: 'vector-db',
    description: 'High-performance vector search engine',
    hosting: 'managed',
    maxDimensions: 65535,
    hybridSearch: true,
    filtering: true,
    supportedRuntimes: ['node', 'bun', 'python', 'rust', 'go'],
    pros: [
      'Excellent performance',
      'Rich filtering',
      'Hybrid search',
      'Written in Rust',
      'Self-host or cloud',
    ],
    cons: [
      'More complex setup',
      'Smaller community than Pinecone',
    ],
    tradeoffs: [
      'Performance vs. ease of use',
      'Features vs. simplicity',
    ],
    bestFor: ['High-performance search', 'Complex filtering', 'Rust enthusiasts'],
    monthlyCost: { free: true, hobbyist: '$25', startup: '$100+', enterprise: 'Custom' },
    requiredEnvVars: ['QDRANT_URL', 'QDRANT_API_KEY'],
    compatibleWith: ['langchain', 'llamaindex'],
    incompatibleWith: [],
    complexity: 'medium',
    logoEmoji: 'ðŸ”·',
    documentationUrl: 'https://qdrant.tech/documentation',
  },
  {
    id: 'weaviate',
    name: 'Weaviate',
    category: 'vector-db',
    description: 'AI-native vector database with GraphQL API',
    hosting: 'managed',
    maxDimensions: 65535,
    hybridSearch: true,
    filtering: true,
    supportedRuntimes: ['node', 'python', 'go'],
    pros: [
      'GraphQL API',
      'Multi-modal support',
      'Hybrid search',
      'Auto-vectorization',
    ],
    cons: [
      'Complex for simple use cases',
      'Higher learning curve',
    ],
    tradeoffs: [
      'Features vs. complexity',
      'GraphQL vs. REST simplicity',
    ],
    bestFor: ['Multi-modal search', 'GraphQL users', 'Auto-vectorization needs'],
    monthlyCost: { free: true, hobbyist: 'Pay-as-you-go', startup: '$100+', enterprise: 'Custom' },
    requiredEnvVars: ['WEAVIATE_URL', 'WEAVIATE_API_KEY'],
    compatibleWith: ['langchain', 'llamaindex'],
    incompatibleWith: [],
    complexity: 'medium',
    logoEmoji: 'ðŸŒ',
    documentationUrl: 'https://weaviate.io/developers/weaviate',
  },
  {
    id: 'turbopuffer',
    name: 'Turbopuffer',
    category: 'vector-db',
    description: 'Fast, low-cost vector database optimized for serverless',
    hosting: 'managed',
    maxDimensions: 4096,
    hybridSearch: false,
    filtering: true,
    supportedRuntimes: ['node', 'bun', 'python'],
    pros: [
      'Very low cost',
      'Fast queries',
      'Simple API',
      'Serverless-friendly',
    ],
    cons: [
      'Fewer features than competitors',
      'Smaller ecosystem',
      'Limited hybrid search',
    ],
    tradeoffs: [
      'Cost vs. features',
      'Simplicity vs. advanced capabilities',
    ],
    bestFor: ['Cost-conscious projects', 'Serverless apps', 'Simple vector search'],
    monthlyCost: { free: true, hobbyist: '$0-10', startup: '$10-50', enterprise: 'Custom' },
    requiredEnvVars: ['TURBOPUFFER_API_KEY'],
    compatibleWith: ['vercel-ai'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸ’¨',
    documentationUrl: 'https://turbopuffer.com/docs',
  },
  {
    id: 'pgvector',
    name: 'pgvector',
    category: 'vector-db',
    description: 'PostgreSQL extension for vector similarity search',
    hosting: 'self-hosted',
    maxDimensions: 16000,
    hybridSearch: true,
    filtering: true,
    supportedRuntimes: ['node', 'bun', 'python', 'go', 'rust'],
    pros: [
      'Use existing Postgres',
      'SQL + vectors',
      'No separate service',
      'ACID compliant',
    ],
    cons: [
      'Not as performant at large scale',
      'Requires Postgres expertise',
      'Limited to Postgres',
    ],
    tradeoffs: [
      'Simplicity vs. dedicated performance',
      'Existing infrastructure vs. specialized DB',
    ],
    bestFor: ['Postgres users', 'Simple vector needs', 'Unified database architecture'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: ['DATABASE_URL'],
    compatibleWith: ['supabase', 'neon', 'postgres-local', 'drizzle', 'prisma'],
    incompatibleWith: ['mysql-local', 'mongodb-local'],
    complexity: 'medium',
    logoEmoji: 'ðŸ˜',
    documentationUrl: 'https://github.com/pgvector/pgvector',
  },
  {
    id: 'none',
    name: 'No Vector Database',
    category: 'vector-db',
    description: 'Skip vector database setup',
    hosting: 'self-hosted',
    maxDimensions: 0,
    hybridSearch: false,
    filtering: false,
    supportedRuntimes: ['node', 'bun', 'deno', 'python', 'go', 'rust'],
    pros: ['Simpler architecture', 'Lower costs'],
    cons: ['No semantic search', 'No RAG capabilities'],
    tradeoffs: ['Simplicity vs. AI features'],
    bestFor: ['Non-RAG apps', 'Traditional search'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: [],
    compatibleWith: [],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸš«',
  },
];

// Embedding options
export const embeddingProviders: EmbeddingOption[] = [
  {
    id: 'openai-embeddings',
    name: 'OpenAI Embeddings',
    category: 'embedding',
    description: 'OpenAI text embedding models',
    type: 'cloud',
    models: ['text-embedding-3-small', 'text-embedding-3-large', 'text-embedding-ada-002'],
    maxTokens: 8191,
    costPer1MTokens: '$0.02-$0.13',
    supportedRuntimes: ['node', 'bun', 'python'],
    pros: [
      'High quality embeddings',
      'Multiple model sizes',
      'Wide ecosystem support',
      'Easy to use',
    ],
    cons: [
      'API costs',
      'Data sent to OpenAI',
      'Rate limits',
    ],
    tradeoffs: [
      'Quality vs. cost',
      'Convenience vs. privacy',
    ],
    bestFor: ['Production RAG', 'Quality-focused apps', 'OpenAI ecosystem'],
    monthlyCost: { free: false, hobbyist: '$1-10', startup: '$10-100', enterprise: 'Custom' },
    requiredEnvVars: ['OPENAI_API_KEY'],
    compatibleWith: ['openai-sdk', 'vercel-ai', 'langchain', 'pinecone', 'chromadb'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸ”¢',
    documentationUrl: 'https://platform.openai.com/docs/guides/embeddings',
  },
  {
    id: 'cohere-embeddings',
    name: 'Cohere Embeddings',
    category: 'embedding',
    description: 'Cohere multilingual embedding models',
    type: 'cloud',
    models: ['embed-english-v3.0', 'embed-multilingual-v3.0', 'embed-english-light-v3.0'],
    maxTokens: 512,
    costPer1MTokens: '$0.10',
    supportedRuntimes: ['node', 'python'],
    pros: [
      'Excellent multilingual support',
      'Input type optimization',
      'Good quality/cost ratio',
    ],
    cons: [
      'Smaller ecosystem',
      'Lower token limit',
    ],
    tradeoffs: [
      'Multilingual vs. English-only quality',
      'Cost vs. OpenAI quality',
    ],
    bestFor: ['Multilingual apps', 'International products', 'Cost-conscious projects'],
    monthlyCost: { free: true, hobbyist: '$0-10', startup: '$10-50', enterprise: 'Custom' },
    requiredEnvVars: ['COHERE_API_KEY'],
    compatibleWith: ['langchain', 'pinecone'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸŒ',
    documentationUrl: 'https://docs.cohere.com/docs/embeddings',
  },
  {
    id: 'voyage-embeddings',
    name: 'Voyage AI',
    category: 'embedding',
    description: 'State-of-the-art embeddings for retrieval',
    type: 'cloud',
    models: ['voyage-large-2', 'voyage-code-2', 'voyage-lite-02-instruct'],
    maxTokens: 16000,
    costPer1MTokens: '$0.10-$0.12',
    supportedRuntimes: ['node', 'python'],
    pros: [
      'Top benchmark performance',
      'Long context support',
      'Code-specific model',
    ],
    cons: [
      'Newer provider',
      'Smaller ecosystem',
    ],
    tradeoffs: [
      'Quality vs. ecosystem maturity',
    ],
    bestFor: ['High-quality retrieval', 'Code search', 'Long documents'],
    monthlyCost: { free: true, hobbyist: '$5-20', startup: '$20-100', enterprise: 'Custom' },
    requiredEnvVars: ['VOYAGE_API_KEY'],
    compatibleWith: ['langchain', 'pinecone'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸš€',
    documentationUrl: 'https://docs.voyageai.com',
  },
  {
    id: 'local-embeddings',
    name: 'Local Embeddings',
    category: 'embedding',
    description: 'Self-hosted embedding models via Ollama or similar',
    type: 'local',
    models: ['nomic-embed-text', 'mxbai-embed-large', 'all-minilm'],
    maxTokens: 8192,
    costPer1MTokens: null,
    supportedRuntimes: ['node', 'python'],
    pros: [
      'No API costs',
      'Data stays local',
      'No rate limits',
      'Privacy',
    ],
    cons: [
      'Requires GPU for speed',
      'Lower quality than cloud',
      'Setup complexity',
    ],
    tradeoffs: [
      'Privacy vs. quality',
      'Cost vs. setup complexity',
    ],
    bestFor: ['Privacy-focused apps', 'Offline apps', 'Cost-sensitive projects'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: ['OLLAMA_HOST'],
    compatibleWith: ['ollama', 'langchain'],
    incompatibleWith: [],
    complexity: 'medium',
    logoEmoji: 'ðŸ ',
    documentationUrl: 'https://ollama.ai',
  },
  {
    id: 'none',
    name: 'No Embeddings',
    category: 'embedding',
    description: 'Skip embedding setup',
    type: 'local',
    models: [],
    maxTokens: 0,
    costPer1MTokens: null,
    supportedRuntimes: ['node', 'bun', 'deno', 'python', 'go', 'rust'],
    pros: ['Simpler setup', 'No costs'],
    cons: ['No semantic search capabilities'],
    tradeoffs: ['Simplicity vs. AI features'],
    bestFor: ['Non-AI apps', 'Keyword search only'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: [],
    compatibleWith: [],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸš«',
  },
];

// Local AI options
export const localAIProviders: LocalAIOption[] = [
  {
    id: 'ollama',
    name: 'Ollama',
    category: 'local-ai',
    description: 'Run local LLMs easily',
    platform: 'cross-platform',
    gpuRequired: false,
    minMemoryGB: 8,
    apiCompatibility: 'openai',
    pros: [
      'Easy setup',
      'OpenAI-compatible API',
      'Many models available',
      'Cross-platform',
      'Active development',
    ],
    cons: [
      'Slower than cloud',
      'Limited to available models',
      'Resource intensive',
    ],
    tradeoffs: [
      'Privacy vs. speed',
      'Cost savings vs. quality',
    ],
    bestFor: ['Local development', 'Privacy-focused apps', 'Offline capabilities'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: ['OLLAMA_HOST'],
    compatibleWith: ['vercel-ai', 'langchain', 'chromadb'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸ¦™',
    documentationUrl: 'https://ollama.ai',
  },
  {
    id: 'lmstudio',
    name: 'LM Studio',
    category: 'local-ai',
    description: 'Desktop app for running local LLMs',
    platform: 'cross-platform',
    gpuRequired: false,
    minMemoryGB: 8,
    apiCompatibility: 'openai',
    pros: [
      'Beautiful UI',
      'Easy model management',
      'OpenAI-compatible API',
      'No coding required',
    ],
    cons: [
      'Desktop app required',
      'Less flexible than CLI',
      'Not for production',
    ],
    tradeoffs: [
      'Ease of use vs. automation',
      'UI vs. scriptability',
    ],
    bestFor: ['Local experimentation', 'Non-technical users', 'Model testing'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: [],
    compatibleWith: ['vercel-ai', 'langchain'],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸ–¥ï¸',
    documentationUrl: 'https://lmstudio.ai',
  },
  {
    id: 'llamacpp',
    name: 'llama.cpp',
    category: 'local-ai',
    description: 'Efficient C++ LLM inference',
    platform: 'cross-platform',
    gpuRequired: false,
    minMemoryGB: 4,
    apiCompatibility: 'openai',
    pros: [
      'Very efficient',
      'Low memory usage',
      'CPU inference viable',
      'Active development',
    ],
    cons: [
      'C++ compilation needed',
      'More technical setup',
      'Manual model management',
    ],
    tradeoffs: [
      'Efficiency vs. ease of use',
      'Control vs. convenience',
    ],
    bestFor: ['Embedded systems', 'Resource-constrained environments', 'Performance optimization'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: [],
    compatibleWith: [],
    incompatibleWith: [],
    complexity: 'high',
    logoEmoji: 'âš¡',
    documentationUrl: 'https://github.com/ggerganov/llama.cpp',
  },
  {
    id: 'mlx',
    name: 'MLX',
    category: 'local-ai',
    description: 'Apple Silicon optimized ML framework',
    platform: 'apple-silicon',
    gpuRequired: true,
    minMemoryGB: 16,
    apiCompatibility: 'custom',
    pros: [
      'Apple Silicon optimized',
      'Unified memory usage',
      'Fast inference',
      'Apple-maintained',
    ],
    cons: [
      'Mac only',
      'Requires Apple Silicon',
      'Smaller ecosystem',
    ],
    tradeoffs: [
      'Performance on Mac vs. portability',
      'Optimization vs. ecosystem size',
    ],
    bestFor: ['Mac developers', 'Apple Silicon machines', 'iOS/macOS ML apps'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: [],
    compatibleWith: [],
    incompatibleWith: [],
    complexity: 'medium',
    logoEmoji: 'ðŸŽ',
    documentationUrl: 'https://ml-explore.github.io/mlx',
  },
  {
    id: 'none',
    name: 'No Local AI',
    category: 'local-ai',
    description: 'Skip local AI setup',
    platform: 'cross-platform',
    gpuRequired: false,
    minMemoryGB: 0,
    apiCompatibility: 'custom',
    pros: ['Simpler setup', 'No hardware requirements'],
    cons: ['No offline AI capabilities'],
    tradeoffs: ['Simplicity vs. local AI'],
    bestFor: ['Cloud-only AI', 'Non-AI apps'],
    monthlyCost: { free: true, hobbyist: null, startup: null, enterprise: null },
    requiredEnvVars: [],
    compatibleWith: [],
    incompatibleWith: [],
    complexity: 'low',
    logoEmoji: 'ðŸš«',
  },
];

// Helper functions
export const getAIFrameworkById = (id: string): AIOption | undefined =>
  aiFrameworks.find(ai => ai.id === id);

export const getVectorDBById = (id: string): VectorDBOption | undefined =>
  vectorDatabases.find(vdb => vdb.id === id);

export const getEmbeddingById = (id: string): EmbeddingOption | undefined =>
  embeddingProviders.find(emb => emb.id === id);

export const getLocalAIById = (id: string): LocalAIOption | undefined =>
  localAIProviders.find(lai => lai.id === id);

export const getAIFrameworksByRuntime = (runtime: string): AIOption[] =>
  aiFrameworks.filter(ai => ai.supportedRuntimes.includes(runtime as any));

export const getManagedVectorDBs = (): VectorDBOption[] =>
  vectorDatabases.filter(vdb => vdb.hosting === 'managed');
